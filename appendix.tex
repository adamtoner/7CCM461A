\part{Appendices}
\begin{appendices}

\section{Notation}

\iffalse
\begin{tabular}{|c|c|c|}
    \hline
    Risk Set & the set of all individuals who are at risk at time $t_{(i)}$ & $\R(t_{(i)})=\R_i$\\
    & the number of elements in the risk set at time $t_{(i)}$ & $r_{(i)}=|\R_i|$ \\
    \hline
    Death Set & the set of all individuals for which an event is observed at time $t_{(i)}$ & $\D(t_{(i)})=\D_i$\\
    & the number of observed events at time $t_{(i)}$ & $m_{(i)}=|\D_i|$\\
    \hline
    Covariates & the covariate vector for individual j & $\z_j$\\
    & the covariate vector for the individual failing at time $t_{(i)}$ & $\z_{(i)}$\\
    \hline
    Survivor Function & the function showing the survival probability of an individual & $\F(t_i)$\\
\end{tabular}
\fi

\section{Schools of Statistical Thought}\label{app:stats-frameworks}

The two primary ways of approaching the problem of model selection are Bayesian and frequentist. I will not go into much detail here regarding the Bayesian-frequentist divide or the benefits of both, for a more in-depth discussion, see Guyon et al \fcite{bayesian-frequentist}. In a majority of cases, a model developed in one framework has an equivalent model in the alternative framework which will give essentially the same result.

A frequesntist thinks of a probability as a long-run frequency with which an event occurs, i.e. sampling is infinite and the data observed is a sample in the universe of possible results. It is normally frequentist statistics that one is taught in school. Maximum likelihood estimation is a frequentist technique which aims to find the parameters of a model which maximise the likelihood function, i.e. the parameters which are most likely to describe the underlying distribution of the random variable given the data observed. 

A Bayesian thinks of probability more akin to the natural way, considering prior information about the distribution of the parameters in the model. Bayesian statistics at its core is centered around Bayes' theorem, given by

\begin{equation}\label{bayes-theorem}
    pr(\Beta|data)=\frac{pr(data|\Beta)\cdot pr(\Beta)}{pr(data)},
\end{equation}

where $pr(\Beta|data)$ is the posterior, $pr(data|\Beta)$ is the likelihood, $pr(\Beta)$ is the prior, and $pr(data)$ is the marginal. 

In the usual process of inference about $\Beta$, $pr(data)$ is excluded from the equation as it contains no information about the parameters. If $pr(data)$ is required, it can be inferred later by integrating over all values of $\Beta$ and equating the integral to $1$. This leaves

\begin{equation}
    pr(\Beta|data)\propto pr(data|\Beta)\cdot pr(\Beta).
\end{equation}

In Bayesian statistics, $\Beta$ is not a point estimate, but is its own distribution. I said above that $pr(\Beta|data)$ is the posterior, this is formally known as the posterior probability distribution: the distribution of the unknown parameter(s) $\Beta$ conditioned on the data available. 

A common technique in Bayesian statistics is to find the Maximum A Posteriori Probability (MAP) Estimation which is used to find an estimate of the parameters $\Beta$ as the mode of the posterior probability distribution. This is akin to MLE in a frequentist framework but takes into consideration the prior distribution of $\Beta$. The prior distribution allows for the quantification of information known from previous or similar events. The MLE and MAP can be characterised as follows:

\begin{align}
    \hat\Beta_{MLE}(data) &= \argmax_{\Beta} f(data|\Beta)\label{mle}\\
    \hat\Beta_{MAP}(data) &= \argmax_{\Beta} f(\Beta|data) = \argmax_{\Beta} f(data|\Beta)g(\Beta)\label{map}
\end{align}

%\section{Gibbs Sampling}
%https://www.tandfonline.com/doi/abs/10.1080/01621459.1993.10476353?src=recsys

\section{Bias-Variance Tradeoff}\label{sec:bias-variance}

%\section{Convex Functions}

\section{Signal-to-Noise Ratio}\label{app:snr}

This section is based on the explanation by Hastie et al \fcite{hastie2017extended}, adapted to fit the notation used in this thesis. The signal to noise ratio is defined to be

\begin{equation}
    SNR = \frac{var(f[\z_0])}{var(\epsilon_0)},
\end{equation}

where $(t_0,\z_0,\delta_0)\in\mathbb{R}^p\times\mathbb{R}\times\{0,1\}$ is a given subject, $f(\z_0=\mathbb{E}(t_0|\z_0)$ and $\epsilon_0 = t_0-f(\z_0)$. Basically, $t_0$ is the actual failure time and $f(\z_0)$ gives the expected failure time given the covariate vector. Considering $f(\z_0)$ gives the expected failure time, $\epsilon_0$ gives the noise of the measurements, i.e. the unexplained variance in the data.

Let a function $g$ be trained on the $n$ samples of the data $(t_i, \z_i, \delta_i)$, for $i=1,\ldots,n$ that are i.i.d to $(t_0, \z_0, \delta_0)$. The associated proportion of variance explained (PVE) of the given prediction function $g$ is defined as

\begin{equation}
    PVE(g)=1-\frac{\mathbb{E}(t_0-g(\z_0))^2}{var(t_0)},
\end{equation}

which is maximised when $g(\cdot)=f(\cdot)$:

\begin{equation}\label{eqn:maximised-pve}
    PVE(f)=1-\frac{var(\epsilon_0)}{var(t_0)}=\frac{SNR}{1+SNR}.
\end{equation}

The second equality of \cref{eqn:maximised-pve} assumed the independence of $\z_0$ and $\epsilon_0$, i.e. it is assumed that the covariates do not affect the distribution of the random unexplained noise, such that $var(t_0)=var(f[\z_0])+var(\epsilon_0)$. Considering the SNR is necessarily nonzero and the PVE is maximised when equal to $\frac{SNR}{1+SNR}$, the range of values bust be

\begin{equation}
    0<PVE \leq \frac{SNR}{1+SNR}.
\end{equation}

Clearly the PVE has the upper bound of 1 given by $\lim_{SNR\xrightarrow{}\infty}\frac{SNR}{1+SNR} = 1$. Hastie et al \fcite{hastie2017extended} analysed the PVE to infer realistic values of the SNR. Given that in most real-world cases, a PVE of 0.2 is fairly typical, they found that the SNRs considered by Bertsimas \fcite{bertsimas2016best} were probably too high and so suggested studying SNRs more in a lower range. In their tests, they estimated the SNR using the LASSO which always estimated it slightly below the population SNR.

\end{appendices}